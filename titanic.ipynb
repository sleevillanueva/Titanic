{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check our data\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length of our data\n",
    "len(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which columns have null values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the types of our columns\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11da6b6d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAECCAYAAAARlssoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzcDO3IZGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da43f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the distribution of Age that are not empty\n",
    "sns.distplot(titanic[titanic[\"Age\"].isnull()!=True].Age.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill the Age with the median because our graph looks a little bit skewed to the right\n",
    "titanic.Age.fillna(value=np.median(titanic[titanic[\"Age\"].isnull()!=True].Age.values),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the cabin column to get rid of the null values.\n",
    "We don't want to drop the rows with cabins that have null values because that consists of 77% of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.drop(\"Cabin\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finally, let's drop the rows for the Embarked column because there are only 2 null values\n",
    "titanic.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we check the null values again\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't have \"objects\" when building our models, so let's take a look at the columns and see which ones might be useful to us. \n",
    "\n",
    "It seems like we can map the gender to 0 and 1.\n",
    "There are three values in Embarked, so we might opt to use dummies.\n",
    "\n",
    "When do we use dummies, and when do we just \"map\" the data?\n",
    "I mapped the Sex in this situation because there were only two values. Dummy variables are basically binary columns from your categorical data. If we make dummy variables for categorical columns with only two values, one of the columns will be redundant because it's basically implying the same thing. I will print out the dummy variables later for the Embarked column so that we can have a better grasp of what get_dummies does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic[\"Sex\"] = titanic[\"Sex\"].map({\"female\":0, \"male\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_dummies = pd.get_dummies(titanic[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C    Q    S\n",
       "0  0.0  0.0  1.0\n",
       "1  1.0  0.0  0.0\n",
       "2  0.0  0.0  1.0\n",
       "3  0.0  0.0  1.0\n",
       "4  0.0  0.0  1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly take a look at the dummy variables above. For the first row, it's telling us that the \"Embarked\" value is \"S\". In the next row, it's \"C\", and the next three rows, the values are \"S\"s.\n",
    "\n",
    "I mentioned a while ago that it doesn't make sense to create dummy variables for two values. The phenomenon in which two variables being highly correlated (which means that one can be linearly predicted from the other with a substantial degree of accuracy) is called collinearity. When this happens to multiple variables, it is called multicollinearity.\n",
    "\n",
    "Why is this important to note? If we are building a model that has two variables highly correlated to one another, the weight is \"doubled\" because you're basically considering the effect of these variables twice. \n",
    "\n",
    "So you can probably say, well, wouldn't this happen to three columns saying the same thing as well? The answer is yes, and normally what we could do is drop one of these columns to avoid that phenomenon. The common practice is to drop the most recurring value that we have, and we can check that out using the value_counts() function. It is important to note that there are models that \"fixes\" this issue without having to drop one of the columns before we do modelling, but we can just leave it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We talked about dropping the column with the highest value count\n",
    "embarked_dummies.drop(titanic[\"Embarked\"].value_counts().index[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection:\n",
    "\n",
    "1. PassengerID -> a unique ID for each of the passengers. It obviously wouldn't make sense as a feature to predict our model because each one is unique.\n",
    "\n",
    "2. Name -> Some people have the same name but normally that wouldn't really be indicative of whether the person would survive or not. You can probably argue that people like presidents, royalty, etc would probably get saved because of their importance, then again, you don't really need a model for that do we?\n",
    "\n",
    "3. Ticket -> Having the same idea about the PassengerId, ticket doesn't really make sense to have as a feature because ticket numbers are usually unique to each passenger.\n",
    "\n",
    "4. Pclass -> This seems okay initially but when we look at the data dictionary, we actually see that 1 represents 1st class, 2 represents second class and 3 represents third class. We see that it's actually a categorical column masking itself as ordinal. Tsk tsk. So what do we do with categorical more than two values? You got it. Make dummies!\n",
    "\n",
    "5. Sibling Spouse -> number of siblings/spouses aboard\n",
    "6. Parch -> number of parents/children aboard\n",
    "7. Fare -> passenger fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's make the dummy variables for Pclass\n",
    "pclass_dummies = pd.get_dummies(titanic[\"Pclass\"])\n",
    "pclass_dummies.drop(titanic[\"Pclass\"].value_counts().index[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's take a look at relationships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Those were a lot of words but good news, we're ready to start modeling! YASSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With concat, I'm just sticking the filtered titanic dataframe to the dummies that were made\n",
    "#for embarked\n",
    "X = pd.concat([titanic[[\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]],embarked_dummies,pclass_dummies], axis=1)\n",
    "y = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's try out K Nearest Neighbors, and we need to split our data to train and test our model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789237668161\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y,random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have an accuracy score of 78.9% for the KNN model. What does that mean? It's basically saying that we can predict correctly 78.9% of the time. Our baseline has an accuracy score of 50% because if I just guessed each time if a person survives or not, I'll be right 50% of the time. \n",
    "\n",
    "Let's take a stab at the most basic classifier which is our Logistic Regression and see if that would give us a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793721973094\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our logistic regression's accuracy is a little bit higher.\n",
    "\n",
    "So what's next? We can still play around with our data. We can decide which columns we want to include as our features and what parameters we should use for our models. But for now, I'll stop here and predict the test data Kaggle gave using my Logistic Regression model and see what score we get from there.\n",
    "\n",
    "Note: I'm going to replace the null values for Fare because we can't drop rows for submission purposes. I'm going to use the median value just like what we did for age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm just going to do the EDA exactly as what we did on top for the test data\n",
    "ttest = pd.read_csv(\"test.csv\")\n",
    "ttest.Age.fillna(value=np.median(ttest[ttest[\"Age\"].isnull()!=True].Age.values),inplace=True)\n",
    "ttest.Fare.fillna(value=np.median(ttest[ttest[\"Fare\"].isnull()!=True].Fare.values),inplace=True)\n",
    "ttest.drop(\"Cabin\",axis=1, inplace=True)\n",
    "ttest[\"Sex\"] = ttest[\"Sex\"].map({\"female\":0, \"male\":1})\n",
    "embarked_dummiestest = pd.get_dummies(ttest[\"Embarked\"])\n",
    "embarked_dummiestest.drop(ttest[\"Embarked\"].value_counts().index[0], axis=1, inplace=True)\n",
    "pclass_dummiestest = pd.get_dummies(ttest[\"Pclass\"])\n",
    "pclass_dummiestest.drop(ttest[\"Pclass\"].value_counts().index[0], axis=1, inplace=True)\n",
    "X_ttest = pd.concat([ttest[[\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]],embarked_dummiestest,pclass_dummiestest], axis=1)\n",
    "X_ttest = StandardScaler().fit_transform(X_ttest)\n",
    "y_testpred = lr.predict(X_ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"PassengerId\":[x for x in range(892,1310)], \"Survived\": y_testpred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save to a csv file\n",
    "submission.to_csv(\"submission3.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. Couldn't help it. Had to try some optimization techniques y'all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 544 candidates, totalling 1632 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:    2.8s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:    5.1s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:    7.9s\n",
      "[Parallel(n_jobs=1)]: Done 1632 out of 1632 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'warm_start': [False, True], 'C': [0.0001, 0.001, 0.01, 0.1, 0.15, 0.25, 0.275, 0.33, 0.5, 0.66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0], 'intercept_scaling': [2, 1], 'fit_intercept': [False, True], 'penalty': ['l1', 'l2'], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "search_parameters = {\n",
    "    \"penalty\":             ['l1','l2'],   #Ridge or Lasso\n",
    "    \"C\":                   [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0],  # Regularization paramter\n",
    "    \"fit_intercept\":       [False, True], # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    \"class_weight\":        [None, \"balanced\"], # The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "    \"intercept_scaling\":   [2, 1],        # Useful only if solver is liblinear. when self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equals to intercept_scaling is appended to the instance vector. \n",
    "    \"warm_start\":          [False, True]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lr, search_parameters, verbose=True)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797525309336\n"
     ]
    }
   ],
   "source": [
    "print grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this again with KNN shall we? We have to remember that for each model, we have to look at the documentation for what the parameters that we can tweak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.727784026997\n"
     ]
    }
   ],
   "source": [
    "search_parameters = {\n",
    "    'n_neighbors':  [3,50], \n",
    "    'weights':      (\"uniform\", \"distance\"),\n",
    "    'algorithm':    (\"ball_tree\", \"kd_tree\", \"brute\", \"auto\"),\n",
    "    'p':            [1,2]\n",
    "}\n",
    "\n",
    "knn_grid = GridSearchCV(knn, search_parameters)\n",
    "\n",
    "# Fit our training data\n",
    "knn_grid.fit(X, y)\n",
    "\n",
    "print \"Best Score:\", knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew. That does not look good for our KNN! I think we should look around and see what the parameters are for our initial KNN and the parameters for the KNN with gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute', 'n_neighbors': 50, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that gridsearch totally changed our initial KNN parameters. One thing we can note is that when we have high n_neighbors, we're looking at 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
